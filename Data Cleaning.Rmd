---
title: "Los Angeles Vehicle Citations Project - Data Cleaning"
author: "Brandon Thoma"
date: "March 22, 2019"
output: html_document
---

# Import Libraries

```{r, message = FALSE, warning = FALSE}
x <- c("dplyr", "magrittr", "stringr", "stringi", "lubridate", "ggplot2",
       "scales", "proj4", "maps", "ggmap", "tidyr", "data.table", "gridExtra")
lapply(x, library, character.only = TRUE)
source("Custom Created Functions.R")
rm(x)
```

# Introduction - Import and Subsetting

```{r, message = FALSE, warning = FALSE}
# The Raw Citations Data can be found at
# https://www.kaggle.com/cityofLA/los-angeles-parking-citations. The data is 
# constantly updated and me be larger than the file I used at the time of this
# project.
raw_data <- fread("Raw Citations Data.csv", sep = ",")
# Remove non-useful columns (for this particular project analysis).
clean_data <- raw_data %>%
  select("Issue Date", "Issue time", "Make", "Location", "Violation code",
         "Violation Description", "Fine amount", "Latitude", "Longitude") %>%
  rename(Issue_Date = `Issue Date`, Issue_Time = `Issue time`,
         Violation_Code = `Violation code`, Fine_Amount = `Fine amount`,
         Violation_Description = `Violation Description`)
```

# Assumptions Going Forward

```{r}
# Tickets are unique, no duplicates. Assume for simplicity that this means 
# that no vehicle was cited more than once in a given instance. 
length(unique(clean_data$`Ticket number`)) == nrow(clean_data)
```

# Issue Date Cleaning

```{r, echo = FALSE}
# Cleanup Issue Date column by removing erroneous timestamp, leaving as
# character for later.
clean_data$Issue_Date <- gsub('T00:00:00', "", clean_data$Issue_Date) 
# Only will look at 2018 for this analysis. The following method is faster than
# subsetting and using format.
clean_data$Year <- year(ymd(clean_data$Issue_Date))
#clean_data <- subset(clean_data, Year == 2018) %>%
#  select(., select = -Year)
clean_data <- clean_data %>%
  filter(Year == 2018) %>%
  #select(., select = -Year)
  select(-Year)
```

# Issue Time Cleaning

```{r}
# Issue Time for the ticket is originally stored in the raw data based on a 
# custom numeric value based on military time that indicates the hour/minutes
# since midnight that the ticket was issued. Cleaned the variable so it stores
# the hours and minutes in proper military time.
clean_data$Issue_Time <- as.character(clean_data$Issue_Time) %>%
  correct_time(clean_data, ., "Issue_Time")
```

# Issue Date-time (New Variable) Creation

```{r}
# New column that stores the date and time.
clean_data$Issue_DT <- apply(clean_data[, c('Issue_Date','Issue_Time')], 1,
                             paste, collapse = " ") %>%
# Some values in the raw data were missing Issue Time (NA), so were quieted to
# not show in output.
  ymd_hm(., quiet = TRUE)
# Change timezone from UTC.
tz(clean_data$Issue_DT) <- 'America/Los_Angeles'
# Now remove unnecessary columns.
clean_data <- clean_data %>%
  select(-c(Issue_Time, Issue_Date))
```

# Tickets by Month and Day, Day of the Week, and Time of Day

```{r}
clean_data$Month <- lubridate::month(clean_data$Issue_DT, label = TRUE)
clean_data$Date <- as.Date(clean_data$Issue_DT, tz = "America/Los_Angeles")
clean_data$Weekday <- weekdays(clean_data$Issue_DT)
# Need to standardize the date to one day to be able to plot citations by time
# of day.
clean_data$TOD <- strftime(clean_data$Issue_DT, format = "%H:%M:%S",
                           tz = "America/Los_Angeles") %>%
  as.POSIXct(., format = "%H:%M:%S")
```

# Latitude and Longitude Coordinate Cleaning

```{r}
# The coordinates in the raw data have latitude / longitude (X/Y) in US Feet
# coordinates according to the NAD_1983_StatePlane_California_V_FIPS_0405_Feet
# projection. We need to change translate these coordinates into a more
# standard format of coordinate to use for Google maps plotting.
# The specific parameters for proj4string is found based on
# https://epsg.io/transform#s_srs=102645&t_srs=4326 and
# https://epsg.io/transform#s_srs=102645&t_srs=4326 pages.
proj4string <- paste('+proj=lcc +lat_1=34.03333333333333',
                     ' +lat_2=35.46666666666667 +lat_0=33.5 +lon_0=-118 ',
                     '+x_0=2000000 +y_0=500000.0000000002 +ellps=GRS80 ',
                     '+datum=NAD83 +to_meter=0.3048006096012192 +no_defs')
projections <- project(clean_data[, c("Latitude", "Longitude")], proj4string,
                       inverse = TRUE)
new_coords <- data.frame(latitude = projections$y, longitude = projections$x)
clean_data$New_Latitude <- new_coords$latitude
clean_data$New_Longitude <- new_coords$longitude
clean_data <- clean_data %>%
  select(-Latitude, - Longitude)
```

# Write Excel Spreadsheets

```{r}
# For date-time columns, will be converted with write.csv, which saves as a
# character for easier conversion back.
fwrite(clean_data, "Cleaned Data.csv", dateTimeAs = "write.csv")
```

# Remove Unecessary Objects

```{r}
rm(raw_data, projections, proj4string, new_coords)
```
